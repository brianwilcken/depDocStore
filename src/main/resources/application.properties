nlp.sentenceDetectorModel=nlp/en-sent.bin
nlp.tokenizerModel=nlp/en-token.bin

nlp.doccatModel=data/DocCat.bin
nlp.doccatTrainingFile=data/doccat.train
nlp.doccatParametersFile_input=nlp/doccat-parameters.bin
nlp.doccatParametersFile_output=data/doccat-parameters.bin

nlp.gibberish.goodEnglish=nlp/gibberish/goodEnglish.txt
nlp.gibberish.badEnglish=nlp/gibberish/badEnglish.txt
nlp.gibberish.bigEnglish=nlp/gibberish/bigEnglish.txt

nlp.stanfordPOSTagger=nlp/english-left3words-distsim.tagger

spellcheck.words=spellcheck/words.txt
spellcheck.words58K=spellcheck/58000words.txt
spellcheck.stopwords=spellcheck/stopwords.txt

tess4j.path=/Tesseract-OCR/tessdata/
use.proxy=@useProxy@
proxy=@proxy.host@
proxyPort=@proxy.port@

solr.url=@index.url@
solr.username=@index.username@
solr.password=@index.password@

mongodb.url=@mongo.url@
mongodb.temporaryFileRepo=@tempFileRepo@

webScraper.autoRefresh=@wsAuto@
webScraper.refreshInterval=@wsInterval@

webCrawler.crawlStorageFolder=C:/webCrawlerStorage/

geonamesIndex.location=/IndexDirectory

wordVectors.location=/WordVectors/GoogleNews-vectors-negative300.bin.gz
#wordVectors.location=/WordVectors/w2v.txt

clarkCluster.exe=/Clark_POS_Induction/cluster_neyessenmorph.exe

textExtraction.pdfGibberishThreshold=0.75
textExtraction.ocrGibberishThreshold=1
#textExtraction.ocrGibberishThreshold=0.1

spring.servlet.multipart.max-file-size=4294967296
spring.servlet.multipart.max-request-size=4294967296
